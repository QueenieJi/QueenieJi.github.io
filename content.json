{"pages":[{"title":"Project","text":"","link":"/project/index.html"}],"posts":[{"title":"Foundation of Concurrency","text":"There are some learning notes about UNSW COMP3151/9154. Main contents are based on Ben Ari’s book Principles of concurrent and distributed programming algorithms and models and lecture slides. Final RevisionLinear Temporal Logic (LTL)A linear temporal property is a set of behaviours. LogicDefinition: A logic is a formal language designed to express logical reasoning. Like any formal language, logics have a syntax and semantics. In concurrency:take time into account SemanticsSemantics are a mathematical representation of the meaning of a piece of syntax. There are many ways of giving a logic semantics, but we will use models. LTLLinear temporal logic (LTL) is a logic designed to describe linear time properties. Modal or temporal operators If $φ$ is an LTL formula, then $\\bigcirc φ$ is an LTL formula.If $φ, ψ$ are LTL formulae, then $φ U ψ$ is an LTL formula. circle: nextU: untildescribe a behaviour $\\bigcirc$No Orange -&gt; it’s not orange right now$\\bigcirc$ Orange -&gt; it’s orange in the next state Uorange U blue -&gt; at some point in the future (don’t have to hold forever and the future can be now) , the right will be true, before that, the left is true LTL SemanticsLet $σ = σ_0σ_1σ_2σ_3σ_4σ_5$ . . . be a behaviour. Then define notation: $σ|_0 = σ$ $σ|_1 = σ_1σ_2σ_3σ_4σ_5 . . . $ $σ|_{n+1} = (σ|_1)|_n$ Semantics The models of LTL are behaviours. For atomic propositions, we just look at the first state. We often identify states with the set of atomic propositions they satisfy. $σ\\vDash p ⇔ p∈σ_0$ $σ\\vDash φ∧ψ ⇔ σ \\vDash φ$ and $σ\\vDashψ$ $σ\\vDash¬φ ⇔ σ\\not\\vDashφ$ $σ|=\\bigcirc φ ⇔σ|_1\\vDashφ$ $σ|=φ U ψ ⇔ $ There exists an $i$ such that $ σ|_i \\vDashψ$ ​ and for all $j &lt; i$, $σ|_j \\vDash φ$ We say $P \\vDash φ$ iff $\\forall \\varphi \\in P$ and $σ \\vDash φ$. Derived Operator The operator $\\Diamond φ$ (“finally” or “eventually”) says that $φ$ will be true at some point. The operator $\\Box \\varphi$ (“globally” or “always”) says that $\\varphi$ is always true from now on. operator diamond =&gt; eventually$\\Diamond φ=$ T $U φ$we don’t care about the left hand side =&gt; True operator box =&gt; for any time from now on, phi will hold $\\Box \\varphi = \\neg \\Diamond \\neg φ$ Exercise: Infinitely Often= always eventually phi= square diamond phi Safety/Liveness A safety property states that something bad does not happen. These are properties that may be violated by a finite prefix of a behaviour. A liveness property states that something good will happen. These are properties that can always be satisfied eventually Kripke Structures (KS)These traces that we have examined are still sequences of actions, not states. Behaviours, however, are sequences of states. Normally, to convert our labelled transition systems into something we can reason about in LTL, we first translate them into an automata called a Kripke Structure. A Kripke structure is a 4-tuple $(S,I,↦,L)$ which contains a set of states $S$, an initial state $I$, a transition relation $↦$ which, unlike a labelled transition system, does not have any action labels on the transitions, and a labelling function $L$ which associates to every state $S$ a (set of) atomic propositions – these are the atomic propositions we use in our LTL formulae. A Kripke structure for an OS process behaviour was actually shown in the lecture on temporal logic in Week 1, I just never told you it was a Kripke structure. Kripke Structures deal with states, not transition actions. This means, to translate from a labelled transition system to a Kripke structure, we need a way to move labels from transitions to states. The simplest translation is due to de Nicola and Vaandrager, where each transition $s_i\\xrightarrow[]{a}s_j$ in the LTS is split into two in the Kripke Structure: $s_i→X$ and $X→s_j$, where X is a new state that is labelled with a. Because this converts existing LTS locations into blank, unlabelled states in the Kripke structure, this introduces problems with the next state operator in LTL. For this reason (and others) we usually consider LTL without the next state operator in this field. Normally with LTL, we require that Kripke structures have no deadlock states, that is, states with no outgoing transitions. The usual solution here is to add a self loop to all terminal states. We can extract our normal notion of a behaviour by using the progress completeness criterion. Because of the restriction above, the progress criterion is equivalent to examining only the infinite runs of the automata. Calculus of Communicating Systems (CCS)LTS Labelled Transition SystemsTransition DiagramsDefinition A transition diagram is a tuple (L,T,s,t) where: L is a set of locations (program counter values). s ∈ L is a entry location. t ∈ L is a exit location. T is a set of transitions. A transition is written as $l_i \\xrightarrow[]{\\text{g;f}} l_j$ where: $l_i$ and $l_j$ are locations. g is a guard Σ → B (state to boolean) f is a state update Σ → Σ. (State to state) Floyd VerificationRecall the definition of a Hoare triple for partial correctness:$${\\varphi} P {ψ}$$This states that if the program P successfully executes from a starting state satisfying $\\varphi$, the result state will satisfy $ψ$. Observe that this is a safety property. Verifying Partial Correctness Given a transition diagram (L,T,s,t): Associate with each location $l ∈ L$ an assertion $Q(l) : Σ → B$. Prove that this assertion network is inductive, that is: For each transition in T $l_i \\xrightarrow[]{\\text{g;f}} l_j$ show that:$$Q(l_i) ∧ g ⇒ Q(l_j) ◦ f$$ Show that $\\varphi ⇒ Q(s)$ and $Q(t) ⇒ ψ$. Adding ConcurrencyParallel Composition Given two processes P and Q with transition diagrams (LP,TP,sP,tP) and (LQ,TQ,sQ,tQ), the parallel composition of $P$ and $Q$, written $P || Q$ is defined as (L,T,s,t) where: $L = L_P × L_Q$ $s = s_Ps_Q $ $t = t_Pt_Q $ $p_iq_i\\xrightarrow[]{\\text{g;f}}p_jq_i ∈ T$ if $p_i \\xrightarrow[]{\\text{g;f}} p_j ∈ TP $ $p_iq_i \\xrightarrow[]{\\text{g;f}} p_iq_j ∈ T$ if $q_i \\xrightarrow[]{\\text{g;f}} q_j ∈ TQ$ is the parallel composition “associative” and “commutative”, that is to define the parallel composition of N processes, we can just iterate parallel composition of 2 processes and no matter how we do it, we arrive at the “same” result? Yes State Space Explosion Problem Then number of locations and transitions grows exponentially as the number of processes increases. We can only use Floyd’s method directly on the parallel composition (product) diagram in the most basic examples. Our Solution We will instead use a method that allows us to define only inductive assertion networks for P and Q individually, and, by proving some non-interference properties derive an inductive network for P || Q automatically. This means we won’t have to draw that large product diagram! Owicki-Gries MethodSteps To show ${ϕ} P || Q {ψ}$: Define local assertion networks P and Q for both processes. Show that they’re inductive. For each location $p ∈ L_P$, show that $P(p)$ is not falsified by any transition of Q. That is, for each $q \\xrightarrow[]{\\text{g;f}} q’ ∈ TQ$: $P(p) ∧ Q(q) ∧ g ⇒ P(p) ◦ f$ Vice versa for Q. Show that $ϕ ⇒ P(s_P) ∧ Q(s_Q)$ and $P(t_P) ∧ Q(t_Q) ⇒ ψ$. One Big InvariantImagine assertion network(s) where every assertion is the same: An invariant. Benefit: We don’t need to prove interference freedom — the local verification conditions already show that the invariant is preserved. Compeleteness criteriaMutual Exclusion/Critical SectionScheduling","link":"/2020/08/09/Foundation%20of%20Concurrency/"},{"title":"建立自己的blog","text":"使用hexo在github page上超级简单快速的搭建一个blog。 Github PageHexoHexo Theme - Icaruslive2d 看板娘Deploy","link":"/2020/08/10/%E5%BB%BA%E7%AB%8B%E8%87%AA%E5%B7%B1%E7%9A%84blog/"}],"tags":[{"name":"Concurrency","slug":"Concurrency","link":"/tags/Concurrency/"},{"name":"blog page","slug":"blog-page","link":"/tags/blog-page/"}],"categories":[{"name":"notes","slug":"notes","link":"/categories/notes/"}]}